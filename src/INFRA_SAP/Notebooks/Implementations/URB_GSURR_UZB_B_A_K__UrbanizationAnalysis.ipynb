{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uzbekistan Uurbanization\n",
    "As part of a project (P162929) looking at urbanization in Uzbekistan, we are generating a number of summary numbers looking at urbanization. These include municipal level numbers comparing change between the cities, and intra city changes using higher resolution imagery.\n",
    "\n",
    "### City-level analysis\n",
    "1. Puga Index\n",
    "2. LEI\n",
    "3. MIT Urban Form (compactness, discontiguity, expandability, polycentricity\n",
    "4. Nighttime Lights (VIIRS and DMSP)\n",
    "5. Built-area change\n",
    "\n",
    "### Sub-city analysis\n",
    "1. City Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, inspect, logging, importlib\n",
    "import rasterio\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import GOSTnets as gn\n",
    "import GOSTnets.load_osm as losm\n",
    "import GOSTnets.calculate_od_raw as calcOD\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.ops import cascaded_union\n",
    "\n",
    "cmd_folder = os.path.join(\"/home/public/Code/GOST\")\n",
    "sys.path.insert(0, cmd_folder)\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import infrasap.market_access as ma\n",
    "import GOSTRocks.misc as misc\n",
    "import GOSTRocks.rasterMisc as rMisc\n",
    "import GOSTRocks.osmMisc as osmMisc\n",
    "import GOSTRocks.Urban.UrbanRaster\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.generate_network_raster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and read in input data\n",
    "national_boundary = \"/home/public/Data/GLOBAL/ADMIN/Admin0_Polys.shp\"\n",
    "national_settlements = \"/home/public/Data/GLOBAL/Population/global_settlement_points_v1_01.shp\"\n",
    "\n",
    "inputAOI = r\"/home/wb411133/data/Country/UZB/UrbanExtents/Urban_Manual_Extents.shp\"\n",
    "UZB_boundary = r\"/home/wb411133/data/Country/UZB/Adm0.shp\"\n",
    "UZB_cities = r\"/home/wb411133/data/Country/UZB/Cities_and_UTS_pop.shp\"\n",
    "outputFolder = r\"/home/wb411133/data/Country/UZB/urban_summaries\"\n",
    "\n",
    "gridded_pop = \"/home/public/Data/GLOBAL/Population/ppp_prj_2020_UZB.tif\"\n",
    "wp_urbanExtents = inputAOI.replace(\".shp\", \"_worldPop_300.csv\")\n",
    "wp_densExtents = inputAOI.replace(\".shp\", \"_worldPop_1500.csv\")\n",
    "\n",
    "viirsFolder = '/home/public/Data/GLOBAL/NighttimeLights/VIIRS_VRT'\n",
    "dmspFolder = '/home/public/Data/GLOBAL/NighttimeLights/DMSP'\n",
    "ghslVRT = '/home/public/Data/GLOBAL/GHSL/ghsl.vrt'\n",
    "floodVRT = '/home/public/Data/COUNTRY/UZB/uzbekistan/CombinedFloodData/FU_PU_Combined.VRT'\n",
    "osmPBF = '/home/public/Data/COUNTRY/UZB/OSM/uzbekistan-latest.osm.pbf'\n",
    "bufferedOSM_pbf = '/home/wb411133/data/Country/UZB/uzbekistan-latest_100km_buffer.osm.pbf'\n",
    "\n",
    "m_proj = {'init':'epsg:3857'} #projection to use when metres are necessary\n",
    "\n",
    "if not os.path.exists(UZB_boundary):\n",
    "    national_data = gpd.read_file(national_boundary)\n",
    "    UZB_b = national_data[national_data['ISO3'] == \"UZB\"]\n",
    "    UZB_b.to_file(UZB_boundary)\n",
    "else:\n",
    "    UZB_b = gpd.read_file(UZB_boundary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in digitized extents, the points from Ildus' collection \n",
    "#    and the gridded population extents, then combine\n",
    "manual_extents = \"/home/wb411133/data/Country/UZB/UrbanExtents/allUrbanSummaries_simplified.shp\"\n",
    "wp_extents =     \"/home/wb411133/data/Country/UZB/UrbanExtents/Urban_Manual_Extents_worldPop_300.csv\"\n",
    "cities =         \"/home/wb411133/data/Country/UZB/Ildus_Cities_2019_12_19.gpkg\"\n",
    "\n",
    "manual_e = gpd.read_file(manual_extents)\n",
    "manual_e = manual_e.loc[:,['Name','geometry']]\n",
    "wp_extents = pd.read_csv(wp_extents)\n",
    "wb_extents_geom = [loads(x) for x in wp_extents['geometry']]\n",
    "wp_extents = gpd.GeoDataFrame(wp_extents.drop(['geometry'], axis=1), geometry = wb_extents_geom, crs = manual_e.crs)\n",
    "cities = gpd.read_file(cities)\n",
    "\n",
    "# Merge manual extents with Ildus Cities and with WP extents\n",
    "manual_e['I_Cities'] = ''\n",
    "manual_e['wp_extents'] = ''\n",
    "wp_extents['ID'] = [str(x) for x in wp_extents['ID']]\n",
    "for idx, row in manual_e.iterrows():\n",
    "    select_cities = cities[cities.intersects(row['geometry'])]\n",
    "    manual_e.loc[idx,'I_Cities'] = \";\".join(select_cities['Adm. Center\\nENGLISH'])\n",
    "    # identify extents from gridded population\n",
    "    select_extents = wp_extents[wp_extents.intersects(row['geometry'])]\n",
    "    if select_extents.shape[0] > 1:\n",
    "        break\n",
    "    manual_e.loc[idx, 'wp_extents'] = \";\".join(select_extents['ID'])\n",
    "    \n",
    "inA = manual_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster Market Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_access = os.path.join(outputFolder, \"seconds_to_cities_2.tif\")\n",
    "cities_access_50k = os.path.join(outputFolder, \"seconds_to_cities_50k_2.tif\")\n",
    "traversal_raster = os.path.join(outputFolder, \"traversal_time.tif\")\n",
    "market_shed_raster = os.path.join(outputFolder, \"traversal_time_marketsheds.tif\")\n",
    "uzb_cities = gpd.read_file(UZB_cities)\n",
    "uzb_cities = uzb_cities.loc[uzb_cities['Lat'] != 0]\n",
    "big_cities = uzb_cities.loc[uzb_cities['y2019'] >= 50000]\n",
    "pop_data = rasterio.open(gridded_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_UZB</th>\n",
       "      <th>Name_ENG</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Region</th>\n",
       "      <th>Type</th>\n",
       "      <th>Adm_center</th>\n",
       "      <th>y2010</th>\n",
       "      <th>y2015</th>\n",
       "      <th>y2019</th>\n",
       "      <th>c20102019</th>\n",
       "      <th>c20102015</th>\n",
       "      <th>c20152019</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Тошкент шаҳар</td>\n",
       "      <td>Tashkent</td>\n",
       "      <td>41.311139</td>\n",
       "      <td>69.279750</td>\n",
       "      <td>Tashkent</td>\n",
       "      <td>city</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2227502.0</td>\n",
       "      <td>2371269.0</td>\n",
       "      <td>2509969.0</td>\n",
       "      <td>112.680886</td>\n",
       "      <td>106.454181</td>\n",
       "      <td>105.849189</td>\n",
       "      <td>POINT (69.27975000000001 41.311139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Нукус ш.</td>\n",
       "      <td>Nukus</td>\n",
       "      <td>42.464722</td>\n",
       "      <td>59.602222</td>\n",
       "      <td>Karakalpakstan</td>\n",
       "      <td>city</td>\n",
       "      <td>2.0</td>\n",
       "      <td>268798.0</td>\n",
       "      <td>298256.0</td>\n",
       "      <td>312385.0</td>\n",
       "      <td>116.215522</td>\n",
       "      <td>110.959159</td>\n",
       "      <td>104.737206</td>\n",
       "      <td>POINT (59.602222 42.464722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Каратау шаҳарча</td>\n",
       "      <td>Karatau</td>\n",
       "      <td>42.089059</td>\n",
       "      <td>60.281151</td>\n",
       "      <td>Karakalpakstan</td>\n",
       "      <td>uts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2652.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>95.889894</td>\n",
       "      <td>90.573152</td>\n",
       "      <td>105.870108</td>\n",
       "      <td>POINT (60.281151 42.089059)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Манғит  ш</td>\n",
       "      <td>Mangit</td>\n",
       "      <td>42.116115</td>\n",
       "      <td>60.061537</td>\n",
       "      <td>Karakalpakstan</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35159.0</td>\n",
       "      <td>34060.0</td>\n",
       "      <td>36519.0</td>\n",
       "      <td>103.868142</td>\n",
       "      <td>96.874200</td>\n",
       "      <td>107.219612</td>\n",
       "      <td>POINT (60.061537 42.116115)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Жумуртов\"  шаҳарча</td>\n",
       "      <td>Jumurtov</td>\n",
       "      <td>42.060298</td>\n",
       "      <td>60.238327</td>\n",
       "      <td>Karakalpakstan</td>\n",
       "      <td>uts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>3366.0</td>\n",
       "      <td>3621.0</td>\n",
       "      <td>96.200850</td>\n",
       "      <td>89.426142</td>\n",
       "      <td>107.575758</td>\n",
       "      <td>POINT (60.238327 42.060298)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name_UZB  Name_ENG        Lat       Long          Region  Type  \\\n",
       "0        Тошкент шаҳар  Tashkent  41.311139  69.279750        Tashkent  city   \n",
       "1             Нукус ш.     Nukus  42.464722  59.602222  Karakalpakstan  city   \n",
       "2      Каратау шаҳарча   Karatau  42.089059  60.281151  Karakalpakstan   uts   \n",
       "3            Манғит  ш    Mangit  42.116115  60.061537  Karakalpakstan  city   \n",
       "4  \"Жумуртов\"  шаҳарча  Jumurtov  42.060298  60.238327  Karakalpakstan   uts   \n",
       "\n",
       "   Adm_center      y2010      y2015      y2019   c20102019   c20102015  \\\n",
       "0         0.0  2227502.0  2371269.0  2509969.0  112.680886  106.454181   \n",
       "1         2.0   268798.0   298256.0   312385.0  116.215522  110.959159   \n",
       "2         0.0     2652.0     2402.0     2543.0   95.889894   90.573152   \n",
       "3         1.0    35159.0    34060.0    36519.0  103.868142   96.874200   \n",
       "4         0.0     3764.0     3366.0     3621.0   96.200850   89.426142   \n",
       "\n",
       "    c20152019                             geometry  \n",
       "0  105.849189  POINT (69.27975000000001 41.311139)  \n",
       "1  104.737206          POINT (59.602222 42.464722)  \n",
       "2  105.870108          POINT (60.281151 42.089059)  \n",
       "3  107.219612          POINT (60.061537 42.116115)  \n",
       "4  107.575758          POINT (60.238327 42.060298)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uzb_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(traversal_raster):\n",
    "    G_loader = losm.OSM_to_network(bufferedOSM_pbf)\n",
    "    G_loader.generateRoadsGDF()\n",
    "    roads = G_loader.roadsGPD \n",
    "    roads['geometry'] = roads['Wkt']\n",
    "    roads['speed'] = roads['infra_type'].map(ma.speed_dict)\n",
    "    roads = roads.sort_values(['speed'])\n",
    "    roads = roads[~roads['speed'].isnull()]\n",
    "    traversal_time = ma.generate_network_raster(pop_data, roads)\n",
    "    traversal_time = traversal_time.astype(pop_data.meta['dtype'])\n",
    "    with rasterio.open(traversal_raster, 'w', **pop_data.meta) as out:\n",
    "        out.write_band(1, traversal_time)\n",
    "else:\n",
    "    network_r = rasterio.open(traversal_raster)\n",
    "    traversal_time = network_r.read()[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.graph as graph\n",
    "mcp = graph.MCP_Geometric(traversal_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:51:59\t1 of 40\n",
      "12:54:01\t2 of 40\n",
      "12:56:02\t3 of 40\n",
      "12:58:04\t4 of 40\n",
      "13:00:05\t5 of 40\n",
      "13:02:07\t6 of 40\n",
      "13:04:07\t7 of 40\n",
      "13:06:07\t8 of 40\n",
      "13:08:00\t9 of 40\n",
      "13:09:53\t10 of 40\n",
      "13:11:46\t11 of 40\n",
      "13:13:51\t12 of 40\n",
      "13:15:56\t13 of 40\n",
      "13:18:00\t14 of 40\n",
      "13:20:05\t15 of 40\n",
      "13:22:09\t16 of 40\n",
      "13:24:13\t17 of 40\n",
      "13:26:20\t18 of 40\n",
      "13:28:27\t19 of 40\n",
      "13:30:21\t20 of 40\n",
      "13:32:15\t21 of 40\n",
      "13:34:09\t22 of 40\n",
      "13:36:04\t23 of 40\n",
      "13:38:10\t24 of 40\n",
      "13:40:17\t25 of 40\n",
      "13:42:22\t26 of 40\n",
      "13:44:25\t27 of 40\n",
      "13:46:25\t28 of 40\n",
      "13:48:29\t29 of 40\n",
      "13:50:30\t30 of 40\n",
      "13:52:30\t31 of 40\n",
      "13:54:33\t32 of 40\n",
      "13:56:34\t33 of 40\n",
      "13:58:34\t34 of 40\n",
      "14:00:36\t35 of 40\n",
      "14:02:31\t36 of 40\n",
      "14:04:28\t37 of 40\n",
      "14:06:24\t38 of 40\n",
      "14:08:19\t39 of 40\n",
      "14:10:23\t40 of 40\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ma)\n",
    "res = ma.generate_market_sheds(network_r, mcp, big_cities, market_shed_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = ma.calculate_travel_time(pop_data, traversal_time, uzb_cities, cities_access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = ma.calculate_travel_time(pop_data, traversal_time, \n",
    "                                 big_cities, \n",
    "                                 cities_access_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ma)\n",
    "threshold = [30 * 60, \n",
    "             60 * 60,\n",
    "             120 * 60]\n",
    "features = ma.generate_feature_vectors(network_r, mcp, big_cities, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.crs = {'init':'epsg:4326'}\n",
    "big_cities['IDX'] = list(range(1, big_cities.shape[0] + 1))\n",
    "features = pd.merge(features, big_cities.loc[:,['IDX','Name_ENG','y2019']], on='IDX')\n",
    "features.to_file(os.path.join(os.path.dirname(traversal_raster), \"traversal_time_extents.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(['NAME'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOSTNets analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract OSM file\n",
    "if not os.path.exists(bufferedOSM_pbf):\n",
    "    uzb_buffered = UZB_b.to_crs(m_proj)\n",
    "    uzb_buffered['geometry'] = uzb_buffered.buffer(10000)\n",
    "    uzb_buffered = uzb_buffered.to_crs({'init': 'epsg:4326'})\n",
    "    globalPbf = '/home/public/Data/GLOBAL/OSM/GLOBAL/planet-latest.osm.pbf'\n",
    "    osmExtract = osmMisc.osmExtraction(osmosisCmd = \"/home/wb411133/Code/Osmosis/bin/osmosis\", tempFile = \"/home/wb411133/data/temp_osm.sh\")\n",
    "    print(osmExtract.extractBoundingBox(globalPbf, bufferedOSM_pbf, uzb_buffered.unary_union, execute=False))\n",
    "\n",
    "if not os.path.exists(UZB_cities):\n",
    "    allCities = gpd.read_file(national_settlements)\n",
    "    uzb_buffered = UZB_b.to_crs(m_proj)\n",
    "    uzb_buffered['geometry'] = uzb_buffered.buffer(10000)\n",
    "    uzb_buffered = uzb_buffered.to_crs(allCities.crs)\n",
    "    \n",
    "    uzb_cities = allCities[allCities.intersects(uzb_buffered.unary_union)]\n",
    "    uzb_cities.to_file(UZB_cities)\n",
    "else:\n",
    "    uzb_cities = gpd.read_file(UZB_cities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_pickle = os.path.join(outputFolder, \"UZB_cleaned_network.pickle\")\n",
    "if not os.path.exists(network_pickle):\n",
    "    # run GOSTnets access analysis\n",
    "    G_loader = losm.OSM_to_network(bufferedOSM_pbf)\n",
    "    G_loader.generateRoadsGDF()\n",
    "    G = G_loader.initialReadIn()\n",
    "\n",
    "    #Remove disconnected subgraphs\n",
    "    largest = 0\n",
    "    graphs = nx.strongly_connected_component_subgraphs(G)\n",
    "    for g in graphs:\n",
    "        if g.number_of_edges() > largest:\n",
    "            largest = g.number_of_edges()\n",
    "            selected = g\n",
    "    G = selected   \n",
    "    G = gn.convert_network_to_time(G, \"length\", road_col=\"infra_type\")\n",
    "    # save processed network to file\n",
    "    nx.write_gpickle(G, network_pickle)\n",
    "else:\n",
    "    G = nx.read_gpickle(network_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cities = cities.loc[:,['Adm. Center\\nENGLISH', 'Adm.Center Population, \\n000 people','geometry']]\n",
    "i_cities.columns = [\"Name\",\"Pop\",\"geometry\"]\n",
    "i_cities[\"Pop\"] = i_cities[\"Pop\"] * 1000\n",
    "i_cities[\"ISO3\"] = \"UZB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create complete cities list\n",
    "not_uzb_i = uzb_cities['ISO3'] != \"UZB\"\n",
    "neighbour_cities = uzb_cities[not_uzb_i]\n",
    "neighbour_cities = neighbour_cities.loc[:,[\"Schnm\",\"Pop\",\"ISO3\",\"geometry\"]]\n",
    "neighbour_cities.columns = [\"Name\",\"Pop\",\"ISO3\",\"geometry\"]\n",
    "all_cities = i_cities.append(neighbour_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate OD\n",
    "origins = inA.copy()\n",
    "origins['geometry'] = inA['geometry'].apply(lambda x: x.centroid)\n",
    "completedOD = gn.Calculate_OD.calculateOD_gdf(G, origins, all_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uzb_index = all_cities['ISO3'] == \"UZB\"\n",
    "not_uzb_i = all_cities['ISO3'] != \"UZB\"\n",
    "\n",
    "allGravity= gn.Calculate_OD.calculate_gravity(completedOD)#, dWeight=uzb_cities['Pop'])\n",
    "uzbOnly   = gn.Calculate_OD.calculate_gravity(completedOD[:,uzb_index])#, dWeight=uzb_cities['Pop'][uzb_index])\n",
    "notuzb    = gn.Calculate_OD.calculate_gravity(completedOD[:,not_uzb_i])#, dWeight=uzb_cities['Pop'][not_uzb_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins['allGravity'] = allGravity['d_0.001']\n",
    "origins['uzbOnlyGravity'] = uzbOnly['d_0.001']\n",
    "origins['notuzbGravity'] = notuzb['d_0.001']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins_gravity = os.path.join(outputFolder, \"all_gravity_calculated.shp\")\n",
    "allGravity_file = os.path.join(outputFolder, \"all_gravity.csv\")\n",
    "uzbOnly_file = os.path.join(outputFolder,    \"uzb_only_gravity.csv\")\n",
    "notuzb_file = os.path.join(outputFolder,     \"not_uzb_gravity.csv\")\n",
    "\n",
    "origins.to_file(origins_gravity)\n",
    "allGravity.to_csv(allGravity_file)\n",
    "uzbOnly.to_csv(uzbOnly_file)\n",
    "notuzb.to_csv(notuzb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gridded analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J:\\Data\\GLOBAL\\ROAD_NETWORKS\\UZB\\output\n",
    "G = nx.read_gpickle(\"/home/public/Data/GLOBAL/ROAD_NETWORKS/UZB/output/UZB_processed.pickle\")\n",
    "G = gn.convert_network_to_time(G, \"length\", road_col='infra_type', factor=1000)\n",
    "# Generate grid for analysis\n",
    "fishnet = os.path.join(outputFolder, \"fishnet_5km.shp\")\n",
    "\n",
    "if not os.path.exists(fishnet):\n",
    "    b = UZB_b.total_bounds\n",
    "    misc.createFishnet(fishnet, b[0], b[2], b[1], b[3], 1000, 1000, crsNum=int(UZB_b.crs['init'].split(\":\")[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = gpd.read_file(fishnet)\n",
    "dests = cities.loc[:,['Adm. Center\\nENGLISH', 'Adm.Center Population, \\n000 people','geometry']]\n",
    "dests.columns = [\"Name\",\"Pop\",\"geometry\"]\n",
    "dests[\"Pop\"] = dests[\"Pop\"] * 1000\n",
    "dests[\"ISO3\"] = \"UZB\"\n",
    "#origins = origins.to_crs(dests.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UZB_b = gpd.read_file(UZB_boundary)\n",
    "origins['geometry'] = origins['geometry'].apply(lambda x: x.centroid)\n",
    "select_origins_index = origins.intersects(UZB_b.unary_union)\n",
    "origins = origins[select_origins_index]\n",
    "origins = origins.to_crs(dests.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completedOD = calcOD.calculateOD_gdf(G, origins, dests, fail_value=999999, calculate_snap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate minimum travel time\n",
    "import numpy as np\n",
    "minimum_drive_time = np.amin(completedOD, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(origins.shape)\n",
    "origins['MinDT'] = minimum_drive_time\n",
    "# Project UZB boundary to WGS84\n",
    "\n",
    "print(origins.shape)\n",
    "origins.to_file(fishnet.replace(\".shp\", \"minimum_drive_time.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_edges = gn.edge_gdf_from_graph(G)\n",
    "road_edges.drop(['Wkt'], axis=1, inplace=True)\n",
    "road_edges.to_file(os.path.join(os.path.dirname(fishnet), \"UZB_Roads.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins.to_file(fishnet.replace(\".shp\", \"minimum_drive_time.shp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate new urban clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.wkt import loads\n",
    "\n",
    "def load_csv_gpd(csv_file, crs={'init':'epsg:4326'}, geom_col = \"geometry\"):\n",
    "    ''' convert a csv file to a geopandas dataset.\n",
    "    \n",
    "    INPUT\n",
    "    csv_file [ string ] - path to csv file\n",
    "    [ optional ] crs [ dictionary ] - CRS dictionary. Default = {'init':'epsg:4326'}\n",
    "    [ optional ] geom_col [ string ] - column storing geometry. Default = 'geometry'\n",
    "    \n",
    "    RETURNS\n",
    "    [geopandas data frame]\n",
    "    '''\n",
    "    inD = pd.read_csv(csv_file, index_col=0)\n",
    "    inD_geom = inD[geom_col].apply(lambda x: loads(x))\n",
    "    inD = gpd.GeoDataFrame(inD.drop([geom_col], axis=1), geometry = inD_geom, crs=crs)\n",
    "    return(inD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(GOSTRocks.Urban.UrbanRaster)\n",
    "wp_urbanExtents = wp_urbanExtents.replace(\".csv\", \"_smoothed.csv\")\n",
    "if not os.path.exists(wp_urbanExtents):\n",
    "    urban_raster = GOSTRocks.Urban.UrbanRaster.urbanGriddedPop(gridded_pop)\n",
    "    urban_extents = urban_raster.calculateVectorUrban(densVal=3)\n",
    "    urban_extents.to_csv(wp_urbanExtents)\n",
    "    #highDens = urban_raster.calculateVectorUrban(densVal=15, totalPopThresh=50000, smooth=True)\n",
    "    #highDens.to_csv(wp_densExtents)\n",
    "else:\n",
    "    urban_extents = load_csv_gpd(wp_urbanExtents)\n",
    "    highDens = load_csv_gpd(wp_densExtents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_raster = GOSTRocks.Urban.UrbanRaster.urbanGriddedPop(gridded_pop)\n",
    "urban_raster.calculateVectorUrban?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admin level zonal stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_boundary = \"/home/public/Data/COUNTRY/UZB/ADMIN/UZB_adm1.shp\"\n",
    "ghsl_file = r\"/home/public/Data/GLOBAL/GHSL/ghsl.vrt\"\n",
    "inA = gpd.read_file(admin_boundary)\n",
    "inG = rasterio.open(ghsl_file)\n",
    "inA = inA.to_crs(inG.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rMisc.zonalStats(inA, ghsl_file, rastType='C', unqVals=[1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pd = pd.DataFrame(res, columns = [\"Water\",\"NotBuilt\",\"Built0014\",\"Built9000\",\"Built7590\",\"BuiltPre75\"])\n",
    "res_pd['NAME'] = inA['NAME_1']\n",
    "res_pd['TYPE'] = inA['TYPE_1']\n",
    "res_pd['ID'] = inA['ID_1']\n",
    "res_pd.to_csv(os.path.join(outputFolder, \"ADMIN0_GHSL_Summary.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City level zonal stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inD = gpd.read_file(inputAOI)\n",
    "viirsOut = os.path.join(outputFolder, \"VIIRS_Summaries\")\n",
    "dmspOut  = os.path.join(outputFolder, \"DMSP_Summaries\")\n",
    "ghslOut  = os.path.join(outputFolder, \"GHSL_Summaries\")\n",
    "popOut   = os.path.join(outputFolder, \"Population_Summaries\")\n",
    "for f in [viirsOut, dmspOut, ghslOut, popOut]:\n",
    "    if not os.path.exists(f):\n",
    "        os.makedirs(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate area of urban extents\n",
    "inD_proj = inD.to_crs(m_proj)\n",
    "inD['areaKM'] = inD_proj['geometry'].apply(lambda x: x.buffer(0).area/1000000)\n",
    "inD.drop(['geometry'], axis=1).to_csv(os.path.join(outputFolder, \"ExtentArea.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal statistics against viirs\n",
    "# Get a list of VIIRS vrt files\n",
    "allVRT = os.listdir(viirsFolder)\n",
    "for VRT in allVRT:\n",
    "    print(VRT)\n",
    "    outFile = os.path.join(viirsOut, VRT.replace(\".vrt\", \".csv\"))\n",
    "    if not os.path.exists(outFile):\n",
    "        xx=rMisc.zonalStats(inD, os.path.join(viirsFolder, VRT), minVal=0.1)\n",
    "        res = pd.DataFrame(xx, columns=['SUM', 'MEAN', 'MAX', 'SD'])\n",
    "        res['Name'] = inD['Name']\n",
    "        res.to_csv(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal statistics against DMSP\n",
    "# get a list of NTL VIIRS\n",
    "allTif = []\n",
    "for root, dirs, files in os.walk(dmspFolder):\n",
    "    for f in files:        \n",
    "        if f[-24:] == \"ElvidgeCorrected_gt3.tif\":\n",
    "            allTif.append(os.path.join(root, f))\n",
    "            \n",
    "for dmsp in allTif:\n",
    "    dmspName = os.path.basename(dmsp)[:7]\n",
    "    outFile = os.path.join(dmspOut, \"%s.csv\" % dmspName)\n",
    "    xx = rMisc.zonalStats(inD, dmsp)\n",
    "    res = pd.DataFrame(xx, columns=['SUM', 'MEAN', 'MAX', 'SD'])\n",
    "    res['Name'] = inD['Name']\n",
    "    res.to_csv(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal statistics against GHSL\n",
    "xx = rMisc.zonalStats(inD, ghslVRT, rastType='C', reProj=True, unqVals=[0,1,2,3,4,5,6])\n",
    "res = pd.DataFrame(xx, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6'])\n",
    "res['Name'] = inD['Name']\n",
    "res.to_csv(os.path.join(ghslOut, \"ghsl.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal statistics against WorldPop\n",
    "xx = rMisc.zonalStats(inD, gridded_pop, rastType='N', reProj=True, minVal=0)\n",
    "res = pd.DataFrame(xx, columns=['SUM', 'MEAN', 'MAX', 'SD'])\n",
    "res['Name'] = inD['Name']\n",
    "res.to_csv(os.path.join(popOut, \"WorldPop.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSummaries = []\n",
    "for f in os.listdir(viirsOut):\n",
    "    curRes = rMisc.zonalResult(os.path.join(viirsOut, f), 'N', fieldAction='JOIN', fieldNames = f.replace(\".csv\",\"\"))\n",
    "    allSummaries.append(curRes)\n",
    "    \n",
    "for f in os.listdir(dmspOut):\n",
    "    curRes = rMisc.zonalResult(os.path.join(dmspOut, f), 'N', fieldAction='JOIN', fieldNames = f.replace(\".csv\",\"\"))\n",
    "    allSummaries.append(curRes)\n",
    "    \n",
    "curRes = rMisc.zonalResult(os.path.join(ghslOut, \"ghsl.csv\"), 'C', fieldAction='JOIN', fieldNames = \"GHSL\")\n",
    "allSummaries.append(curRes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRes = allSummaries[0].inValues\n",
    "for x in allSummaries[1:]:\n",
    "    cVals = x.inValues\n",
    "    cols = [c for c in cVals.columns if not \"Name\" in c]\n",
    "    allRes = allRes.join(x.inValues[cols])\n",
    "allRes = allRes.join(inD)\n",
    "allRes.to_csv(os.path.join(outputFolder, \"allUrbanSummaries.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Urbanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersect the urban extents with the WP gridded extents\n",
    "urbanProj = urban_extents.to_crs(m_proj)\n",
    "inD_proj = inD.to_crs(m_proj)\n",
    "urbanArea = urbanProj.unary_union\n",
    "area_res = []\n",
    "for idx, row in inD_proj.iterrows():\n",
    "    #get interseting urban areas\n",
    "    interArea = row['geometry'].intersection(urbanArea)\n",
    "    area_res.append(interArea.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inD['area_urban_m'] = area_res\n",
    "inD.drop(['geometry'], axis=1).to_csv(os.path.join(outputFolder, \"ExtentArea_Urban.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Nighttime Lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output files\n",
    "baseline_ntl = os.path.join(viirsFolder, 'VIIRS_201208.vrt')\n",
    "end_ntl1 = os.path.join(viirsFolder, 'VIIRS_201808.vrt')\n",
    "end_ntl2 = os.path.join(viirsFolder, 'VIIRS_201904.vrt')\n",
    "ntl_out_folder = os.path.join(outputFolder, \"VIIRS_Data\")\n",
    "if not os.path.exists(ntl_out_folder):\n",
    "    os.makedirs(ntl_out_folder)\n",
    "ntlT0_file = os.path.join(ntl_out_folder, \"VIIRS_201208.tif\")\n",
    "ntlT1_file = os.path.join(ntl_out_folder, \"VIIRS_201808.tif\")\n",
    "ntlT2_file = os.path.join(ntl_out_folder, \"VIIRS_201904.tif\")\n",
    "ntl_T1_diff = os.path.join(ntl_out_folder, \"VIIRS_diff_201208_201808.tif\")\n",
    "ntl_T2_diff = os.path.join(ntl_out_folder, \"VIIRS_diff_201208_201904.tif\")\n",
    "\n",
    "# Project UZB boundary to WGS84\n",
    "UZB_extent = UZB_b.to_crs({'init':'epsg:4326'})\n",
    "\n",
    "#Clip T0, T1, T2\n",
    "rMisc.clipRaster(rasterio.open(baseline_ntl), UZB_extent, ntlT0_file)\n",
    "rMisc.clipRaster(rasterio.open(end_ntl1), UZB_extent, ntlT1_file)\n",
    "rMisc.clipRaster(rasterio.open(end_ntl2), UZB_extent, ntlT2_file)\n",
    "\n",
    "#Write out difference files\n",
    "ntlT0 = rasterio.open(ntlT0_file)\n",
    "ntlT1 = rasterio.open(ntlT1_file)\n",
    "ntlT2 = rasterio.open(ntlT2_file)\n",
    "if not os.path.exists(ntl_T1_diff):\n",
    "    with rasterio.open(ntl_T1_diff, 'w', **ntlT0.profile) as dst:\n",
    "        dst.write(ntlT1.read() - ntlT0.read())        \n",
    "if not os.path.exists(ntl_T2_diff):\n",
    "    with rasterio.open(ntl_T2_diff, 'w', **ntlT0.profile) as dst:\n",
    "        dst.write(ntlT2.read() - ntlT0.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract GHSL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghsl_vrt = \"/home/public/Data/GLOBAL/GHSL/ghsl.vrt\"\n",
    "g_rast = rasterio.open(ghsl_vrt)\n",
    "ghsl_out_folder = os.path.join(outputFolder, \"GHSL_Data\")\n",
    "if not os.path.exists(ghsl_out_folder):\n",
    "    os.makedirs(ghsl_out_folder)\n",
    "out_GHSL = os.path.join(ghsl_out_folder, \"ghsl.tif\")\n",
    "if not os.path.exists(out_GHSL):\n",
    "    UZB_extent = UZB_b.to_crs(g_rast.crs)\n",
    "    rMisc.clipRaster(g_rast, UZB_extent, out_GHSL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntl_T1_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City Scan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(osmMisc)\n",
    "importlib.reload(GOSTRocks.Urban.UrbanAnalysis)\n",
    "city_scan_folders = '/home/wb411133/data/Country/UZB/city_scans/'\n",
    "for idx, row in inA.iterrows():\n",
    "    curCity = row['Name']\n",
    "    outFolder = os.path.join(city_scan_folders, curCity)\n",
    "    if not os.path.exists(outFolder):\n",
    "        os.makedirs(outFolder)\n",
    "    inputAOI = os.path.join(outFolder, \"AOI.shp\")\n",
    "    gpd.GeoDataFrame([row], crs=inA.crs).to_file(inputAOI)\n",
    "    gridsize = 250\n",
    "    #Generate OSM PBF for city\n",
    "    out_osm_pbf = os.path.join(outFolder, \"local.osm.pbf\")  \n",
    "    if not os.path.exists(out_osm_pbf):        \n",
    "        osmExtract = osmMisc.osmExtraction()\n",
    "        x = osmExtract.extractBoundingBox(osmPBF, out_osm_pbf, row['geometry'], execute=True)\n",
    "    else:\n",
    "        ua = GOSTRocks.Urban.UrbanAnalysis.urbanAnalysis(inShape=inputAOI, \n",
    "                     urbanFolder=outFolder, \n",
    "                     gridSize=gridsize)\n",
    "        ua.MarketAccess(osmPBF=out_osm_pbf, churches=False)\n",
    "        ua.prepMappingData(clipRasters=True)\n",
    "    print(curCity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(GOSTRocks.Urban.UrbanAnalysis)\n",
    "importlib.reload(osmMisc)\n",
    "ua = GOSTRocks.Urban.UrbanAnalysis.urbanAnalysis(inShape=inputAOI, \n",
    "                     urbanFolder=outFolder, \n",
    "                     gridSize=gridsize)\n",
    "ua.MarketAccess(osmPBF=out_osm_pbf, churches=False)\n",
    "#xx = osmMisc.convertOSMPBF_DataFrame(out_osm_pbf, 'points', ua.inputAOI_WGS84.unary_union)\n",
    "#xx = ua.osm_pois_file('Health', ['clinic','pharmacy','hospital','health'], out_osm_pbf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geog)",
   "language": "python",
   "name": "geog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
